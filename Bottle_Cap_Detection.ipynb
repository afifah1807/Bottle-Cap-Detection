{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Bottle Cap Detection**\n",
        "\n",
        "***Model Development, Experimentation, and Evaluation***\n",
        "\n",
        "\n",
        "This notebook provides a step-by-step explanation of the process of developing an object detection model to detect bottle cap colors: dark blue, light blue, and mixed/others.\n",
        "\n",
        "The model was trained using YOLOv8 Nano, optimized for edge-device inference (target ‚â§ 10 ms), using a small dataset that was strengthened through augmentation and intensive preprocessing."
      ],
      "metadata": {
        "id": "FRTDLKYhHAlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n",
        "\n",
        "## **1.   Introduction**\n",
        "\n",
        "This project focuses on building an automated system to detect the color of bottle caps using deep learning.  \n",
        "The primary objectives include:\n",
        "\n",
        "###  Project Goals\n",
        "1. Dataset preparation, labeling, preprocessing, and augmentation.\n",
        "2. Training an optimized YOLOv8 nano model using transfer learning.\n",
        "3. Performing model evaluation and performance analysis.\n",
        "4. Running inference tests and optimizing inference speed for edge devices such as Raspberry Pi.\n",
        "\n",
        "YOLOv8n (Nano) is selected due to its efficiency and fast inference time."
      ],
      "metadata": {
        "id": "Af9avbiqMbDz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Dataset and Data Preparation**\n",
        "\n",
        "**Original Dataset**\n",
        "The given dataset initially contained 12 images https://drive.google.com/file/d/1vbMFTe2E5OHp2h5o_YL-RUoIFKxsrZWT, and I manually added 3 additional images:\n",
        "- dark blue bottle cap\n",
        "- light blue bottle cap\n",
        "- mixed dark‚Äìlight blue bottle cap\n",
        "\n",
        "**Preprocessing Steps**\n",
        "\n",
        "| Preprocessing | Description |\n",
        "|--------------|-------------|\n",
        "| Auto-orient | Ensures correct rotation based on EXIF data |\n",
        "| Resize | Creates uniform image dimensions |\n",
        "| Auto-adjust contrast | Enhances visibility under varied lighting |\n",
        "| Tile 2√ó2 | Generates additional samples by tiling the image |\n",
        "\n",
        "**Augmentation Pipeline**\n",
        "\n",
        "| Augmentation | Purpose |\n",
        "|--------------|---------|\n",
        "| Flip | Orientation diversity |\n",
        "| 90¬∞ Rotation | Simulates rotated scenes |\n",
        "| Saturation | Varies color intensity |\n",
        "| Brightness | Simulates lighting variations |\n",
        "\n",
        "**Final Dataset Statistics**\n",
        "\n",
        "After preprocessing + augmentation:\n",
        "\n",
        "- Total images: 148  \n",
        "- Train: 132  \n",
        "- Validation: 12  \n",
        "- Test: 4  \n",
        "\n",
        "This approach is essential due to the small size of the original dataset.\n"
      ],
      "metadata": {
        "id": "KDmq5YMEZF6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLlaI_VgMejK",
        "outputId": "f0f1ecfa-3ca6-413b-9bac-454aee4ca3ac"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.232-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.232-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.232 ultralytics-thop-2.0.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"VggbhYZy22TlPnh2s5qA\")\n",
        "project = rf.workspace(\"afifah-apriliani-yurs5\").project(\"bottle-cap-detection-nndn0\")\n",
        "version = project.version(12)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "id": "0FqHYxhHZWGf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5599f747-d345-402c-956a-3e547328f557"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.12/dist-packages (1.2.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.11.12)\n",
            "Requirement already satisfied: idna==3.7 in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.7)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.10.0.84 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.10.0.84)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Requirement already satisfied: pi-heif<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: pillow-avif-plugin<2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "def count_dataset_files(main_folder_path: str):\n",
        "    \"\"\"\n",
        "    Menghitung jumlah file gambar (.jpg) dan label (.txt)\n",
        "    di sub-folder 'train', 'valid', dan 'test' dalam dataset.\n",
        "\n",
        "    Args:\n",
        "        main_folder_path (str): Path ke folder utama dataset (misalnya, 'Bottle-Cap-Detection-12').\n",
        "    \"\"\"\n",
        "    # Menggunakan Path untuk penanganan path yang lebih baik\n",
        "    base_path = Path(main_folder_path)\n",
        "\n",
        "    # Memastikan folder utama ada\n",
        "    if not base_path.is_dir():\n",
        "        print(f\"ERROR: Folder utama tidak ditemukan di: {main_folder_path}\")\n",
        "        return\n",
        "\n",
        "    # Struktur data untuk menyimpan hasil perhitungan\n",
        "    stats = defaultdict(lambda: {\"images\": 0, \"labels\": 0})\n",
        "\n",
        "    # Sub-folder yang akan dianalisis\n",
        "    data_splits = [\"train\", \"valid\", \"test\"]\n",
        "\n",
        "    print(f\"Menganalisis Struktur Dataset di: {main_folder_path}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for split in data_splits:\n",
        "        split_path = base_path / split\n",
        "\n",
        "        # Paths ke folder images dan labels\n",
        "        images_path = split_path / \"images\"\n",
        "        labels_path = split_path / \"labels\"\n",
        "\n",
        "        # Periksa apakah folder split ada\n",
        "        if not split_path.is_dir():\n",
        "            print(f\"Peringatan: Folder '{split}' tidak ditemukan, melewati.\")\n",
        "            continue\n",
        "\n",
        "        # 1. Hitung file gambar (.jpg)\n",
        "        if images_path.is_dir():\n",
        "            image_count = len(list(images_path.glob(\"*.jpg\")))\n",
        "            # Catatan: Tambahkan \"*.png\" atau format lain jika diperlukan\n",
        "            stats[split][\"images\"] = image_count\n",
        "        else:\n",
        "            print(f\"Peringatan: Folder 'images' di '{split}' tidak ditemukan.\")\n",
        "\n",
        "        # 2. Hitung file label (.txt)\n",
        "        if labels_path.is_dir():\n",
        "            label_count = len(list(labels_path.glob(\"*.txt\")))\n",
        "            stats[split][\"labels\"] = label_count\n",
        "        else:\n",
        "            print(f\"Peringatan: Folder 'labels' di '{split}' tidak ditemukan.\")\n",
        "\n",
        "    ## Hasil Statistik\n",
        "    print(\"\\nHasil Statistik Dataset Bottle-Cap-Detection-12:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"| {'Dataset Split':<15} | {'Jumlah Gambar (.jpg)':<25} | {'Jumlah Label (.txt)':<15} |\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    total_images = 0\n",
        "    total_labels = 0\n",
        "\n",
        "    for split in data_splits:\n",
        "        img_count = stats[split][\"images\"]\n",
        "        lbl_count = stats[split][\"labels\"]\n",
        "\n",
        "        total_images += img_count\n",
        "        total_labels += lbl_count\n",
        "\n",
        "        print(f\"| {split:<15} | {img_count:<25} | {lbl_count:<15} |\")\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"| {'TOTAL':<15} | {total_images:<25} | {total_labels:<15} |\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# Tentukan folder utama dataset Anda\n",
        "MAIN_DATA_FOLDER = \"Bottle-Cap-Detection-12\"\n",
        "\n",
        "# Jalankan fungsi\n",
        "count_dataset_files(MAIN_DATA_FOLDER)"
      ],
      "metadata": {
        "id": "WHFkyvIiZZ2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a62fc79-86f6-4b92-8203-10de070aa6bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menganalisis Struktur Dataset di: Bottle-Cap-Detection-12\n",
            "----------------------------------------\n",
            "\n",
            "Hasil Statistik Dataset Bottle-Cap-Detection-12:\n",
            "============================================================\n",
            "| Dataset Split   | Jumlah Gambar (.jpg)      | Jumlah Label (.txt) |\n",
            "============================================================\n",
            "| train           | 132                       | 132             |\n",
            "| valid           | 12                        | 12              |\n",
            "| test            | 4                         | 4               |\n",
            "============================================================\n",
            "| TOTAL           | 148                       | 148             |\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Model Selection: YOLOv8 Nano**\n",
        "\n",
        "### Why YOLOv8n?\n",
        "YOLOv8 Nano is highly efficient and suitable for real-time detection on constrained hardware.\n",
        "\n",
        "### Advantages\n",
        "‚úî Very fast inference (3‚Äì10 ms)  \n",
        "‚úî Small model size (<9 MB)  \n",
        "‚úî Well-suited for transfer learning on small datasets  \n",
        "\n",
        "### Limitations\n",
        "‚úò Lower accuracy compared to larger YOLO variants  \n",
        "‚úò Sensitive to lighting variations (important for color detection)  \n"
      ],
      "metadata": {
        "id": "z7sU6kyAZuc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Training Configuration**\n",
        "\n",
        "The model is fine-tuned with the following parameters:\n",
        "\n",
        "- **Epochs:** 250  \n",
        "- **Image Size:** 416  \n",
        "- **Batch Size:** 16  \n",
        "- **Early Stopping Patience:** 50  \n",
        "- **Learning Rate:** 0.0001 (reduced to prevent overfitting)  \n",
        "\n",
        "### Additional Augmentations\n",
        "The following augmentations improve generalization:\n",
        "\n",
        "- HSV color jitter\n",
        "- Mosaic (0.5)\n",
        "- Mixup (0.1)\n",
        "- Copy-paste augmentation\n",
        "- Random rotation, shear, and perspective transform\n",
        "\n",
        "This configuration is optimized for **small-data training** with heavy augmentation.\n"
      ],
      "metadata": {
        "id": "BeCJLqnKZ49-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Bottle Cap Detection Training Script\n",
        "Optimized for edge device inference (5-10ms target)\n",
        "Optimized for Small Dataset (100 samples)\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import wandb\n",
        "from datetime import datetime\n",
        "import time\n",
        "import cv2\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. Configuration\n",
        "# ==============================================================================\n",
        "# Sesuaikan parameter ini\n",
        "CONFIG = {\n",
        "    'model': 'yolov8n.pt',  # Ganti ke YOLOv8 Nano: Model yang stabil dan cepat\n",
        "    'data': 'Bottle-Cap-Detection-12/data.yaml',\n",
        "    'epochs': 250,          # Mengurangi epoch awal, biarkan Early Stopping yang bekerja\n",
        "    'imgsz': 320,           # Input size, bisa dicoba 320 untuk kecepatan ekstrem\n",
        "    'batch': 16,            # Batch size ideal\n",
        "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
        "    'patience': 50,         # Ditingkatkan. Lebih sabar untuk dataset kecil\n",
        "    'save_period': 50,\n",
        "    'project': 'runs/train_bottle_cap',\n",
        "    'name': f'yolov8n_cap_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}',\n",
        "\n",
        "    # üí• Augmentation: Ditingkatkan untuk mengatasi dataset 100 sampel (Sangat Penting!)\n",
        "    # Nilai di bawah ini adalah default/direkomendasikan untuk dataset kecil\n",
        "    'hsv_h': 0.015,\n",
        "    'hsv_s': 0.7,\n",
        "    'hsv_v': 0.4,\n",
        "    'degrees': 15.0,        # Rotasi lebih besar\n",
        "    'translate': 0.15,\n",
        "    'scale': 0.7,           # Skala lebih bervariasi\n",
        "    'shear': 5.0,           # Geseran lebih besar\n",
        "    'perspective': 0.0005,  # Sedikit perspektif\n",
        "    'flipud': 0.1,          # Sedikit flip vertikal\n",
        "    'fliplr': 0.5,\n",
        "    'mosaic': 0.5,          # Mengurangi Mosaic agar lebih banyak gambar asli terlihat\n",
        "    'mixup': 0.1,           # Diaktifkan. Penting untuk dataset kecil!\n",
        "    'copy_paste': 0.1,      # Diaktifkan (membutuhkan segmen mask di data.yaml)\n",
        "\n",
        "    # Fine-Tuning Optimization (Sangat Penting untuk Transfer Learning)\n",
        "    'lr0': 0.0001,          # Learning Rate Awal DITURUNKAN drastis untuk fine-tuning\n",
        "    'lrf': 0.01,\n",
        "    'momentum': 0.937,\n",
        "    'weight_decay': 0.0005,\n",
        "}\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. Fungsi Utama Pelatihan\n",
        "# ==============================================================================\n",
        "def train_model():\n",
        "    \"\"\"Train YOLOv8 model for bottle cap detection\"\"\"\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(\"üöÄ Bottle Cap Detection Training (YOLOv8n)\")\n",
        "    print(f\"Dataset Size: ~100. Augmentation is CRUCIAL.\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Device: {CONFIG['device']}\")\n",
        "    print(f\"Base Model: {CONFIG['model']} (Pre-trained)\")\n",
        "    print(f\"Fine-Tuning LR: {CONFIG['lr0']}\")\n",
        "    print(f\"Patience (Early Stop): {CONFIG['patience']}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Initialize Weights & Biases\n",
        "    wandb.init(\n",
        "        project=\"bottle-cap-detection\",\n",
        "        config=CONFIG,\n",
        "        name=CONFIG['name']\n",
        "    )\n",
        "\n",
        "    # Load model (YOLOv8n pre-trained on COCO)\n",
        "    # Ini melakukan Transfer Learning\n",
        "    model = YOLO(CONFIG['model'])\n",
        "\n",
        "    # Train\n",
        "    results = model.train(\n",
        "        data=CONFIG['data'],\n",
        "        epochs=CONFIG['epochs'],\n",
        "        imgsz=CONFIG['imgsz'],\n",
        "        batch=CONFIG['batch'],\n",
        "        device=CONFIG['device'],\n",
        "        patience=CONFIG['patience'],\n",
        "        save_period=CONFIG['save_period'],\n",
        "        project=CONFIG['project'],\n",
        "        name=CONFIG['name'],\n",
        "\n",
        "        # Augmentation (dikutip dari CONFIG)\n",
        "        **{k: CONFIG[k] for k in CONFIG if k in ['hsv_h', 'hsv_s', 'hsv_v', 'degrees', 'translate', 'scale', 'shear', 'perspective', 'flipud', 'fliplr', 'mosaic', 'mixup', 'copy_paste']},\n",
        "\n",
        "        # Optimization (dikutip dari CONFIG)\n",
        "        optimizer='Adam',\n",
        "        lr0=CONFIG['lr0'],\n",
        "        lrf=CONFIG['lrf'],\n",
        "        momentum=CONFIG['momentum'],\n",
        "        weight_decay=CONFIG['weight_decay'],\n",
        "\n",
        "        # Other\n",
        "        plots=True,\n",
        "        verbose=False, # Set False untuk output yang lebih bersih, True untuk detail\n",
        "    )\n",
        "\n",
        "    # Validation setelah pelatihan selesai\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"üìä Validating final model...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Log hasil ke W&B di akhir\n",
        "    final_val_results = model.val()\n",
        "\n",
        "    # Log metrik final ke W&B\n",
        "    wandb.log({\n",
        "        \"final_mAP50\": final_val_results.box.map50,\n",
        "        \"final_mAP50-95\": final_val_results.box.map,\n",
        "    })\n",
        "\n",
        "    # Save best model path\n",
        "    best_model_path = os.path.join(CONFIG['project'], CONFIG['name'], \"weights\", \"best.pt\")\n",
        "    print(f\"\\n‚úÖ Best model saved: {best_model_path}\")\n",
        "\n",
        "    return model, results, best_model_path\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. Fungsi Benchmarking dan Export (Tidak berubah, sudah bagus)\n",
        "# ==============================================================================\n",
        "\n",
        "def benchmark_inference(model_path, test_image='tes2.jpg', num_runs=100):\n",
        "    \"\"\"\n",
        "    Benchmark inference speed\n",
        "    ... (Fungsi ini tetap sama)\n",
        "    \"\"\"\n",
        "    # (Isi fungsi benchmark_inference Anda di sini)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"‚ö° Benchmarking Inference Speed\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    img = cv2.imread(test_image)\n",
        "    if img is None:\n",
        "        print(f\"‚ö†Ô∏è Test image not found: {test_image}. Skipping benchmark.\")\n",
        "        return 0, 0\n",
        "\n",
        "    print(\"Warming up...\")\n",
        "    for _ in range(10):\n",
        "        _ = model(img, imgsz=CONFIG['imgsz'], verbose=False)\n",
        "\n",
        "    print(f\"Running {num_runs} inferences...\")\n",
        "    times = []\n",
        "\n",
        "    for _ in range(num_runs):\n",
        "        start = time.time()\n",
        "        _ = model(img, imgsz=CONFIG['imgsz'], verbose=False)\n",
        "        end = time.time()\n",
        "        times.append((end - start) * 1000)\n",
        "\n",
        "    avg_time = sum(times) / len(times)\n",
        "    min_time = min(times)\n",
        "    max_time = max(times)\n",
        "    fps = 1000 / avg_time\n",
        "\n",
        "    print(f\"\\nüìä Inference Statistics:\")\n",
        "    print(f\"Average: {avg_time:.2f} ms\")\n",
        "    print(f\"Min: {min_time:.2f} ms\")\n",
        "    print(f\"Max: {max_time:.2f} ms\")\n",
        "    print(f\"FPS: {fps:.2f}\")\n",
        "\n",
        "    if avg_time <= 10:\n",
        "        print(f\"‚úÖ PASSED: {avg_time:.2f}ms ‚â§ 10ms target\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è FAILED: {avg_time:.2f}ms > 10ms target\")\n",
        "        print(\"üí° Consider:\")\n",
        "        print(\" ¬† - Export to ONNX/TensorRT\")\n",
        "        print(\" ¬† - INT8 quantization\")\n",
        "        print(\" ¬† - Smaller input size (e.g., 320x320, adjust CONFIG['imgsz'])\")\n",
        "\n",
        "    wandb.log({\n",
        "        \"avg_inference_time_ms\": avg_time,\n",
        "        \"min_inference_time_ms\": min_time,\n",
        "        \"max_inference_time_ms\": max_time,\n",
        "        \"fps\": fps\n",
        "    })\n",
        "\n",
        "    return avg_time, fps\n",
        "\n",
        "\n",
        "def export_optimized_model(model_path):\n",
        "    \"\"\"\n",
        "    Export model to optimized formats for edge deployment\n",
        "    ... (Fungsi ini tetap sama)\n",
        "    \"\"\"\n",
        "    # (Isi fungsi export_optimized_model Anda di sini)\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"üì¶ Exporting Optimized Models\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # Export to ONNX\n",
        "    print(\"\\nüîß Exporting to ONNX...\")\n",
        "    onnx_path = model.export(format='onnx', imgsz=CONFIG['imgsz'], simplify=True)\n",
        "    print(f\"‚úÖ ONNX model saved: {onnx_path}\")\n",
        "\n",
        "    # Export to TorchScript\n",
        "    print(\"\\nüîß Exporting to TorchScript...\")\n",
        "    torchscript_path = model.export(format='torchscript', imgsz=CONFIG['imgsz'])\n",
        "    print(f\"‚úÖ TorchScript model saved: {torchscript_path}\")\n",
        "\n",
        "    # Try TensorRT export (if available)\n",
        "    try:\n",
        "        print(\"\\nüîß Exporting to TensorRT...\")\n",
        "        # Gunakan 'half=True' untuk FP16 (lebih cepat)\n",
        "        trt_path = model.export(format='engine', imgsz=CONFIG['imgsz'], half=True)\n",
        "        print(f\"‚úÖ TensorRT model saved: {trt_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è TensorRT export failed: {e}\")\n",
        "        print(\" ¬† (This is normal if TensorRT is not installed)\")\n",
        "\n",
        "    return onnx_path\n",
        "\n",
        "\n",
        "def analyze_model_performance(model_path, data_yaml):\n",
        "    \"\"\"\n",
        "    Analyze model performance per class\n",
        "    ... (Fungsi ini tetap sama)\n",
        "    \"\"\"\n",
        "    # (Isi fungsi analyze_model_performance Anda di sini)\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"üîç Analyzing Per-Class Performance\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    model = YOLO(model_path)\n",
        "    # Gunakan split='val' untuk konsistensi\n",
        "    results = model.val(data=data_yaml, split='val', verbose=True)\n",
        "\n",
        "    # Ambil nama kelas dari file data.yaml (lebih dinamis)\n",
        "    class_names = results.names\n",
        "\n",
        "    print(\"\\nPer-Class Metrics:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Cek apakah metrik per kelas tersedia\n",
        "    if results.box.ap.shape[0] > 0:\n",
        "        for i, name in class_names.items():\n",
        "            # Pastikan indeks ada\n",
        "            if i < len(results.box.ap):\n",
        "                print(f\"Class {i} ({name}):\")\n",
        "                print(f\" ¬†Precision: {results.box.p[i]:.4f}\")\n",
        "                print(f\" ¬†Recall: {results.box.r[i]:.4f}\")\n",
        "                print(f\" ¬†mAP@50: {results.box.ap50[i]:.4f}\")\n",
        "                print(f\" ¬†mAP@50-95: {results.box.ap[i]:.4f}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Per-Class metrics not available. Check your validation set.\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. Eksekusi\n",
        "# ==============================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Pastikan OpenCV tersedia untuk benchmarking\n",
        "    try:\n",
        "        import cv2\n",
        "    except ImportError:\n",
        "        print(\"ERROR: OpenCV (cv2) not installed. Cannot run benchmark.\")\n",
        "        exit()\n",
        "\n",
        "    # Inisialisasi CV2 untuk menghindari error\n",
        "    try:\n",
        "        # Coba inisialisasi modul time/CV2\n",
        "        pass\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Train model\n",
        "    model, results, best_model_path = train_model()\n",
        "\n",
        "    # Benchmark inference\n",
        "    benchmark_inference(best_model_path)\n",
        "\n",
        "    # Export optimized model\n",
        "    export_optimized_model(best_model_path)\n",
        "\n",
        "    # Analyze performance\n",
        "    analyze_model_performance(best_model_path, CONFIG['data'])\n",
        "\n",
        "    # Finish W&B run\n",
        "    if wandb.run:\n",
        "        wandb.finish()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"‚úÖ Training Complete!\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"Best model: {best_model_path}\")\n",
        "    print(\"\\nNext steps:\")\n",
        "    print(\"1. Check W&B dashboard for detailed metrics\")\n",
        "    print(\"2. Test inference on sample images\")\n",
        "    print(\"3. Deploy to edge device for real-world testing\")"
      ],
      "metadata": {
        "id": "pL4HZ38hRzYw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15808cb8-1406-45c6-8654-4de29da3fec6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "üöÄ Bottle Cap Detection Training (YOLOv8n)\n",
            "Dataset Size: ~100. Augmentation is CRUCIAL.\n",
            "==================================================\n",
            "Device: cpu\n",
            "Base Model: yolov8n.pt (Pre-trained)\n",
            "Fine-Tuning LR: 0.0001\n",
            "Patience (Early Stop): 50\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">yolov8n_cap_20251125_140123</strong> at: <a href='https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection/runs/4k70w0bv' target=\"_blank\">https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection/runs/4k70w0bv</a><br> View project at: <a href='https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection' target=\"_blank\">https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251125_140123-4k70w0bv/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.0"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251125_140200-uf3lsujy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection/runs/uf3lsujy' target=\"_blank\">yolov8n_cap_20251125_140200</a></strong> to <a href='https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection' target=\"_blank\">https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection/runs/uf3lsujy' target=\"_blank\">https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection/runs/uf3lsujy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.232 üöÄ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.1, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Bottle-Cap-Detection-12/data.yaml, degrees=15.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=250, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.1, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=yolov8n_cap_20251125_140200, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=50, perspective=0.0005, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/train_bottle_cap, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/train_bottle_cap/yolov8n_cap_20251125_140200, save_frames=False, save_json=False, save_period=50, save_txt=False, scale=0.7, seed=0, shear=5.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.15, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 4.8MB/s 0.2s\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 322.5¬±85.8 MB/s, size: 18.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Bottle-Cap-Detection-12/train/labels... 132 images, 6 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 132/132 1.2Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Bottle-Cap-Detection-12/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.1¬±0.1 ms, read: 304.9¬±107.4 MB/s, size: 10.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Bottle-Cap-Detection-12/valid/labels... 12 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 1.3Kit/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Bottle-Cap-Detection-12/valid/labels.cache\n",
            "Plotting labels to /content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.0001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 320 train, 320 val\n",
            "Using 0 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/train_bottle_cap/yolov8n_cap_20251125_140200\u001b[0m\n",
            "Starting training for 250 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/250         0G      1.296      3.336      1.116         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.4s/it 30.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.4s/it 1.4s\n",
            "                   all         12         29     0.0217      0.895      0.231      0.156\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      2/250         0G      1.332      2.629       1.12         13        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.4s/it 30.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.8s/it 1.8s\n",
            "                   all         12         29     0.0464      0.445      0.227       0.11\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      3/250         0G      1.312       2.52      1.151         12        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.7s/it 33.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 2.0s/it 2.0s\n",
            "                   all         12         29    0.00398      0.447      0.235      0.148\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      4/250         0G      1.228      2.313      1.143         26        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 27.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3s/it 1.3s\n",
            "                   all         12         29    0.00271      0.474      0.231      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      5/250         0G      1.306      2.297      1.099          6        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.9s/it 35.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29     0.0719      0.974      0.663      0.448\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      6/250         0G      1.285      2.164      1.046         10        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.6s/it 32.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29     0.0223          1      0.658      0.456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      7/250         0G      1.204      2.024      1.103         23        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29     0.0231          1      0.651      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      8/250         0G      1.182      1.917      1.082         30        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29     0.0317          1      0.664      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      9/250         0G      1.194      1.869      1.064         29        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29     0.0431          1      0.699      0.434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     10/250         0G      1.258      1.811      1.096         21        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.5s/it 31.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29     0.0378          1      0.703      0.422\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     11/250         0G      1.157      1.765      1.085         14        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.557      0.653      0.754      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     12/250         0G      1.155      1.803      1.054         26        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.2s/it 1.2s\n",
            "                   all         12         29      0.521      0.718      0.783      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     13/250         0G      1.155      1.697      1.053         20        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.464      0.789      0.792      0.545\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     14/250         0G      1.152      1.765      1.038         13        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.5s/it 31.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.494      0.894      0.799      0.577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     15/250         0G      1.161      1.682      1.037         12        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.2s/it 1.2s\n",
            "                   all         12         29      0.505      0.945      0.814      0.571\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     16/250         0G      1.119      1.613       1.05         14        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.498      0.947      0.842      0.572\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     17/250         0G      1.088      1.629      1.035         35        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 5.2s/it 47.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.501      0.895      0.857      0.563\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     18/250         0G      1.109      1.578      1.018         22        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 4.0s/it 35.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.554      0.868      0.876      0.573\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     19/250         0G       1.05      1.526      1.066         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 4.7s/it 42.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.587      0.868      0.895      0.593\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     20/250         0G      1.083      1.513      1.075          9        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.629      0.895      0.939      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     21/250         0G      1.164      1.572      1.079         34        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.647       0.92      0.964      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     22/250         0G      1.034      1.503      1.017          9        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.651      0.919      0.967      0.681\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     23/250         0G      1.087      1.454      1.016         11        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 30.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.675      0.913      0.973      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     24/250         0G      1.075      1.502      1.067         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.771      0.916      0.978      0.724\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     25/250         0G      1.138      1.491       1.07         18        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.771      0.919      0.981      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     26/250         0G      1.058      1.433      1.032         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3s/it 1.3s\n",
            "                   all         12         29      0.768      0.966      0.981      0.705\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     27/250         0G      1.117      1.452      1.003         33        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.5s/it 31.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.926      0.821      0.986      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     28/250         0G      1.033      1.387     0.9943         11        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.7s/it 33.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.9s/it 1.9s\n",
            "                   all         12         29      0.954      0.788       0.99      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     29/250         0G      1.089      1.426      1.068         16        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.4s/it 30.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.2s/it 1.2s\n",
            "                   all         12         29      0.857      0.906       0.99      0.705\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     30/250         0G      1.099      1.422      1.051          6        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.934      0.937      0.993      0.708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     31/250         0G      1.028      1.358      1.026          8        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.959      0.968      0.993      0.717\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     32/250         0G      1.026      1.311      1.029         18        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3s/it 1.3s\n",
            "                   all         12         29      0.966      0.974      0.994      0.709\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     33/250         0G      1.035      1.292      1.012         14        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.969      0.974      0.994      0.706\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     34/250         0G      1.047      1.341      1.081          7        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.968      0.974      0.993      0.734\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     35/250         0G      1.006      1.291      1.015         10        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.966      0.974      0.993      0.776\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     36/250         0G      1.089      1.224      1.012         22        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.963      0.969      0.991      0.788\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     37/250         0G       1.08      1.213      1.034         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.961      0.971      0.992      0.787\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     38/250         0G      1.054      1.219      1.026         11        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.958      0.966      0.992      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     39/250         0G      1.041      1.192      1.045         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3s/it 1.3s\n",
            "                   all         12         29      0.956      0.968      0.993      0.767\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     40/250         0G      1.073      1.145      1.016         40        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29       0.96      0.974      0.994       0.71\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     41/250         0G     0.9872      1.163      1.003         12        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 30.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.959      0.974      0.994      0.717\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     42/250         0G      1.062      1.221      1.056         17        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.955      0.974      0.994      0.735\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     43/250         0G      1.016      1.138      1.035         36        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.4s/it 1.4s\n",
            "                   all         12         29      0.958      0.992      0.995      0.765\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     44/250         0G     0.9981      1.022     0.9716         12        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.957       0.99      0.995      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     45/250         0G      1.066      1.093      1.027         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.957      0.989      0.995       0.76\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     46/250         0G     0.9826      1.025     0.9751         13        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.957       0.99      0.995      0.759\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     47/250         0G     0.9717      1.047     0.9766         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3s/it 1.3s\n",
            "                   all         12         29      0.957      0.988      0.995      0.777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     48/250         0G     0.9994      1.074     0.9922          9        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.4s/it 30.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.6s/it 1.6s\n",
            "                   all         12         29      0.967      0.947       0.99       0.79\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     49/250         0G     0.9854      1.052      1.013         13        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29       0.97      0.948       0.99      0.799\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     50/250         0G      1.091      1.074      1.025          8        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.973      0.942      0.987      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     51/250         0G      1.024      1.019      1.038         21        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.4s/it 1.4s\n",
            "                   all         12         29      0.972      0.941      0.984        0.8\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     52/250         0G     0.9961     0.9822     0.9926         18        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.973      0.921      0.978      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     53/250         0G     0.9545     0.9719     0.9832         22        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.936      0.921      0.971       0.77\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     54/250         0G      1.008     0.9847     0.9912         10        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.944      0.918       0.97      0.766\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     55/250         0G      1.038          1      1.021         23        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.928      0.921      0.967      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     56/250         0G      1.006     0.9479      1.026          6        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.4s/it 1.4s\n",
            "                   all         12         29      0.929      0.921      0.968      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     57/250         0G      1.016       1.02      1.007         30        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.956      0.921      0.975      0.791\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     58/250         0G     0.9986      1.013     0.9994         38        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.971      0.921       0.98      0.793\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     59/250         0G     0.9819      0.991      1.009          7        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.938      0.967      0.986      0.798\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     60/250         0G     0.9337     0.8924     0.9673         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.956      0.974       0.99       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     61/250         0G     0.9947     0.9885      1.037          9        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.962      0.974       0.99      0.817\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     62/250         0G     0.9505     0.9246     0.9877         20        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.964      0.974       0.99      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     63/250         0G     0.9793     0.9868      1.026         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.967      0.974      0.992      0.806\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     64/250         0G     0.9667     0.9596      1.017         14        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.967      0.974      0.992      0.798\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     65/250         0G     0.9799     0.9339      0.969         25        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.4s/it 31.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.968      0.974      0.991      0.804\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     66/250         0G     0.9949     0.9111     0.9904         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.967      0.973      0.991      0.793\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     67/250         0G     0.9628     0.9519     0.9828         11        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.968      0.974      0.991      0.799\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     68/250         0G     0.9314     0.8882     0.9691         20        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.966      0.974      0.991      0.825\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     69/250         0G     0.9818      0.901     0.9956         35        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3s/it 1.3s\n",
            "                   all         12         29      0.969      0.974      0.991      0.823\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     70/250         0G     0.9922     0.9354     0.9878         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29       0.97      0.972      0.991      0.822\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     71/250         0G     0.9954      0.935     0.9865         32        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29       0.97      0.969      0.991      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     72/250         0G     0.9281     0.9211     0.9903         20        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29       0.97      0.968      0.991      0.827\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     73/250         0G      1.008     0.9684      1.016         40        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.982      0.947      0.989      0.821\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     74/250         0G      1.013     0.9078      1.003         37        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.981      0.946      0.985      0.813\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     75/250         0G     0.9204     0.8537     0.9686         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.981      0.945      0.986      0.805\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     76/250         0G     0.9502     0.9271     0.9916         10        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.979      0.945      0.987      0.776\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     77/250         0G      1.017      0.922     0.9717          7        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.966      0.967      0.988      0.769\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     78/250         0G     0.9209     0.8315     0.9645         32        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.966      0.967      0.987      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     79/250         0G     0.9439     0.8929     0.9959         14        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.965      0.967      0.987      0.811\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     80/250         0G     0.9578     0.8671     0.9871         24        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.969      0.944      0.985      0.831\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     81/250         0G      1.035     0.9112      1.053         32        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.963      0.968      0.988       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     82/250         0G     0.9602     0.8826     0.9983         32        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.4s/it 1.4s\n",
            "                   all         12         29      0.962      0.967      0.988       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     83/250         0G      0.962     0.9705     0.9909          5        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29       0.96      0.968      0.989      0.836\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     84/250         0G     0.9331     0.8317     0.9613         26        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.958      0.974       0.99      0.809\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     85/250         0G      1.014     0.9393      1.062          6        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.955      0.974      0.991      0.813\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     86/250         0G     0.9436     0.8597     0.9829         13        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3s/it 1.3s\n",
            "                   all         12         29      0.957      0.974      0.991      0.812\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     87/250         0G     0.9529     0.8383     0.9697         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.966      0.974      0.988      0.824\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     88/250         0G     0.9416     0.8563     0.9619         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29       0.97      0.946      0.987      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     89/250         0G     0.9833     0.8825     0.9841         35        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.994      0.924      0.986      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     90/250         0G      1.019      0.883     0.9989         25        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.993      0.924      0.986      0.856\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     91/250         0G     0.9767     0.8106     0.9915         16        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29       0.99      0.925      0.984      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     92/250         0G     0.9047     0.8278      0.954         11        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.985      0.929      0.984      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     93/250         0G     0.9046     0.8006     0.9586          8        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.984      0.929      0.983      0.823\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     94/250         0G     0.9375     0.7999     0.9824         13        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.989      0.924      0.985      0.833\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     95/250         0G     0.9688     0.8319     0.9742         20        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.2s/it 1.2s\n",
            "                   all         12         29       0.99      0.924      0.986      0.837\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     96/250         0G     0.9146     0.8323     0.9428          5        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.992      0.923      0.989      0.849\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     97/250         0G     0.9435     0.8375     0.9798          9        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.992      0.923      0.989       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     98/250         0G     0.9511      0.831      1.042         11        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.993      0.923      0.989      0.837\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K     99/250         0G     0.9368     0.9234     0.9874          3        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.993      0.923       0.99      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    100/250         0G          1     0.8583      1.013         24        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.4s/it 1.4s\n",
            "                   all         12         29      0.992      0.924      0.993      0.831\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    101/250         0G     0.9308     0.8139     0.9612         39        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.955      0.963      0.993      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    102/250         0G     0.9505     0.8301     0.9914         20        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.956      0.965      0.993      0.843\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    103/250         0G      0.971     0.9124      1.035          4        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.959      0.964      0.992      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    104/250         0G     0.9453     0.8138     0.9982          6        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.963      0.966      0.993      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    105/250         0G     0.9291     0.8084      0.978         27        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.965      0.967      0.992      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    106/250         0G     0.9255     0.7957     0.9505         22        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.966      0.968      0.992      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    107/250         0G     0.9265     0.8135     0.9931         29        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.965      0.968      0.992      0.821\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    108/250         0G     0.9497     0.8235     0.9829         16        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.976      0.944      0.991      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    109/250         0G     0.8697     0.8451     0.9911         10        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.975      0.945      0.993      0.778\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    110/250         0G     0.9138     0.8064     0.9623         12        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.974      0.945      0.993      0.779\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    111/250         0G     0.8855     0.7632     0.9736         11        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.974      0.945       0.99      0.798\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    112/250         0G     0.9881     0.8116      1.026         37        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.958      0.971      0.995      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    113/250         0G     0.9206     0.8309     0.9673         35        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.959      0.971      0.995      0.848\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    114/250         0G     0.9049     0.8109     0.9904          8        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.959      0.971      0.995      0.846\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    115/250         0G     0.9133     0.8078      1.006         10        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.958      0.972      0.995      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    116/250         0G     0.8954      0.835     0.9715         22        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.958      0.973      0.995      0.834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    117/250         0G     0.9043     0.7998      0.959         18        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29       0.96      0.973      0.995      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    118/250         0G     0.8515     0.7783     0.9663         16        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.959      0.984      0.995      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    119/250         0G     0.8856     0.7768     0.9621         28        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.2s/it 1.2s\n",
            "                   all         12         29       0.96      0.981      0.995      0.864\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    120/250         0G     0.9849     0.8491      1.005         27        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.961      0.978      0.995      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    121/250         0G     0.9116     0.8049     0.9762          8        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.963       0.97      0.994      0.859\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    122/250         0G     0.9407     0.8265      0.985         27        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.963       0.97      0.994      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    123/250         0G     0.8844     0.7943     0.9738         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.963       0.97      0.994      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    124/250         0G     0.9561     0.8587     0.9727          5        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.959      0.981      0.995       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    125/250         0G     0.9441     0.7841     0.9794         14        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29       0.96      0.984      0.995      0.837\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    126/250         0G     0.8813     0.7841     0.9595         12        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.965       0.97      0.994      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    127/250         0G     0.9404     0.8033     0.9617          9        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.966       0.97      0.994      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    128/250         0G     0.9047     0.7416     0.9808         21        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.967       0.97      0.992      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    129/250         0G     0.9656     0.7627      1.009         14        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.967       0.97      0.993      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    130/250         0G       0.93     0.7502     0.9963         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.966       0.97      0.993      0.829\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    131/250         0G     0.8996     0.8187      0.957         26        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.966       0.97      0.992      0.806\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    132/250         0G     0.8958      0.745     0.9645         17        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.4s/it 1.4s\n",
            "                   all         12         29      0.964       0.97      0.993      0.784\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    133/250         0G      0.957     0.7705      1.013         12        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.962       0.97      0.994      0.777\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    134/250         0G     0.8779     0.7833     0.9672         17        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.962       0.97      0.994      0.776\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    135/250         0G     0.9781     0.7966      1.009          9        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.963       0.97      0.994      0.782\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    136/250         0G     0.9456     0.7627     0.9594         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.958      0.991      0.995      0.792\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    137/250         0G     0.9324     0.7873     0.9735         18        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.958      0.993      0.995      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    138/250         0G     0.8922     0.7458     0.9815         26        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.958      0.993      0.995      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    139/250         0G     0.8865     0.7291     0.9438         16        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.958      0.993      0.995      0.812\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    140/250         0G     0.9575     0.8056     0.9838         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.957      0.993      0.995      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    141/250         0G     0.9138     0.7501     0.9758          9        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 27.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.957      0.991      0.995      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    142/250         0G     0.9027     0.7872     0.9554         12        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.2s/it 1.2s\n",
            "                   all         12         29      0.957       0.99      0.995      0.801\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    143/250         0G     0.8751     0.7273       0.94         21        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.957      0.989      0.995      0.807\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    144/250         0G      0.883     0.7321     0.9517         26        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.957      0.988      0.995       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    145/250         0G     0.9188     0.7725     0.9934         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.956      0.978      0.995      0.841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    146/250         0G     0.8648     0.7729      0.966         13        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29      0.956      0.973      0.995      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    147/250         0G     0.8938     0.7562     0.9583         15        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.3s/it 1.3s\n",
            "                   all         12         29      0.956      0.972      0.995      0.838\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    148/250         0G     0.9372     0.7859     0.9757          8        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.956      0.972      0.995      0.844\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    149/250         0G     0.8855     0.7631     0.9573         14        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.957      0.972      0.995      0.848\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    150/250         0G     0.8965     0.7393     0.9859         22        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.957      0.972      0.995      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    151/250         0G     0.9033      0.784     0.9576         10        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.6s/it 1.6s\n",
            "                   all         12         29      0.958       0.97      0.994      0.854\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    152/250         0G     0.9097     0.7567     0.9499          7        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 29.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.958       0.97      0.994      0.852\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    153/250         0G     0.9455     0.7912     0.9465         10        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.958       0.97      0.994      0.847\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    154/250         0G     0.9131     0.7996      1.011         16        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.959       0.97      0.994      0.828\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    155/250         0G     0.8842     0.7608     0.9717          7        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.957      0.981      0.995      0.823\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    156/250         0G     0.8736      0.718     0.9643         19        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.3s/it 29.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.5s/it 1.5s\n",
            "                   all         12         29      0.958       0.99      0.995      0.833\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    157/250         0G     0.8952     0.7558     0.9756         20        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.958       0.99      0.995      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    158/250         0G     0.9231     0.8071     0.9582         22        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.958      0.991      0.995       0.84\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    159/250         0G     0.9519     0.7538     0.9707         32        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.959      0.992      0.995      0.839\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    160/250         0G     0.9184     0.7561     0.9585         30        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.2s/it 1.2s\n",
            "                   all         12         29      0.968      0.971      0.994      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    161/250         0G      0.943     0.7936      0.992         24        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.2s/it 1.2s\n",
            "                   all         12         29      0.967      0.971      0.994      0.842\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    162/250         0G      0.935     0.7635      1.005         14        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.966       0.97      0.994      0.851\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    163/250         0G     0.9039     0.7307     0.9538         32        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.965       0.97      0.994      0.853\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    164/250         0G     0.9064     0.7224     0.9801         14        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.966       0.97      0.994      0.835\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    165/250         0G     0.8621     0.7457     0.9485         13        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.4s/it 1.4s\n",
            "                   all         12         29       0.96      0.986      0.995       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    166/250         0G     0.8648     0.7098     0.9438         18        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0s/it 1.0s\n",
            "                   all         12         29      0.959      0.989      0.995      0.802\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    167/250         0G     0.8783     0.7641     0.9587         20        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.1s/it 28.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.959       0.99      0.995      0.797\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    168/250         0G     0.9193     0.7464     0.9655         41        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29      0.958      0.992      0.995       0.81\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K    169/250         0G     0.9193     0.7928     0.9449          7        320: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9/9 3.2s/it 28.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29       0.96      0.983      0.995      0.811\n",
            "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 50 epochs. Best results observed at epoch 119, best model saved as best.pt.\n",
            "To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
            "\n",
            "169 epochs completed in 1.430 hours.\n",
            "Optimizer stripped from /content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.pt...\n",
            "Ultralytics 8.3.232 üöÄ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29       0.96      0.981      0.995      0.864\n",
            "Speed: 0.7ms preprocess, 77.6ms inference, 0.0ms loss, 8.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/train_bottle_cap/yolov8n_cap_20251125_140200\u001b[0m\n",
            "\n",
            "==================================================\n",
            "üìä Validating final model...\n",
            "==================================================\n",
            "Ultralytics 8.3.232 üöÄ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 411.8¬±111.3 MB/s, size: 10.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Bottle-Cap-Detection-12/valid/labels.cache... 12 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 9.8Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.0it/s 1.0s\n",
            "                   all         12         29       0.96      0.981      0.995      0.864\n",
            "            light blue          8         19          1      0.963      0.995      0.807\n",
            "                 other          4         10       0.92          1      0.995       0.92\n",
            "Speed: 0.6ms preprocess, 68.9ms inference, 0.0ms loss, 6.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n",
            "\n",
            "‚úÖ Best model saved: runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.pt\n",
            "\n",
            "==================================================\n",
            "‚ö° Benchmarking Inference Speed\n",
            "==================================================\n",
            "‚ö†Ô∏è Test image not found: tes2.jpg. Skipping benchmark.\n",
            "\n",
            "==================================================\n",
            "üì¶ Exporting Optimized Models\n",
            "==================================================\n",
            "\n",
            "üîß Exporting to ONNX...\n",
            "Ultralytics 8.3.232 üöÄ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "üí° ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (5.9 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<=1.19.1', 'onnxslim>=0.1.71', 'onnxruntime'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 14 packages in 288ms\n",
            "Prepared 6 packages in 5.35s\n",
            "Installed 6 packages in 377ms\n",
            " + colorama==0.4.6\n",
            " + coloredlogs==15.0.1\n",
            " + humanfriendly==10.0\n",
            " + onnx==1.19.1\n",
            " + onnxruntime==1.24.0.dev20251031003\n",
            " + onnxslim==0.1.75\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 6.8s\n",
            "WARNING ‚ö†Ô∏è \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 22...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.75...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 8.8s, saved as 'runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.onnx' (11.6 MB)\n",
            "\n",
            "Export complete (9.1s)\n",
            "Results saved to \u001b[1m/content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.onnx imgsz=320  \n",
            "Validate:        yolo val task=detect model=runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.onnx imgsz=320 data=Bottle-Cap-Detection-12/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "‚úÖ ONNX model saved: runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.onnx\n",
            "\n",
            "üîß Exporting to TorchScript...\n",
            "Ultralytics 8.3.232 üöÄ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (5.9 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.9.0+cu126...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success ‚úÖ 1.8s, saved as 'runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.torchscript' (11.8 MB)\n",
            "\n",
            "Export complete (2.2s)\n",
            "Results saved to \u001b[1m/content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.torchscript imgsz=320  \n",
            "Validate:        yolo val task=detect model=runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.torchscript imgsz=320 data=Bottle-Cap-Detection-12/data.yaml  \n",
            "Visualize:       https://netron.app\n",
            "‚úÖ TorchScript model saved: runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.torchscript\n",
            "\n",
            "üîß Exporting to TensorRT...\n",
            "WARNING ‚ö†Ô∏è TensorRT requires GPU export, automatically assigning device=0\n",
            "Ultralytics 8.3.232 üöÄ Python-3.12.12 torch-2.9.0+cu126 \n",
            "‚ö†Ô∏è TensorRT export failed: Invalid CUDA 'device=0' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n",
            "\n",
            "torch.cuda.is_available(): False\n",
            "torch.cuda.device_count(): 0\n",
            "os.environ['CUDA_VISIBLE_DEVICES']: \n",
            "See https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
            "\n",
            " ¬† (This is normal if TensorRT is not installed)\n",
            "\n",
            "==================================================\n",
            "üîç Analyzing Per-Class Performance\n",
            "==================================================\n",
            "Ultralytics 8.3.232 üöÄ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 374.1¬±209.1 MB/s, size: 10.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Bottle-Cap-Detection-12/valid/labels.cache... 12 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 12/12 8.6Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1/1 1.1s/it 1.1s\n",
            "                   all         12         29       0.96      0.981      0.995      0.864\n",
            "            light blue          8         19          1      0.963      0.995      0.807\n",
            "                 other          4         10       0.92          1      0.995       0.92\n",
            "Speed: 2.7ms preprocess, 78.1ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val2\u001b[0m\n",
            "\n",
            "Per-Class Metrics:\n",
            "--------------------------------------------------\n",
            "Class 0 (dark blue):\n",
            " ¬†Precision: 1.0000\n",
            " ¬†Recall: 0.9630\n",
            " ¬†mAP@50: 0.9950\n",
            " ¬†mAP@50-95: 0.8069\n",
            "Class 1 (light blue):\n",
            " ¬†Precision: 0.9196\n",
            " ¬†Recall: 1.0000\n",
            " ¬†mAP@50: 0.9950\n",
            " ¬†mAP@50-95: 0.9204\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>final_mAP50</td><td>‚ñÅ</td></tr><tr><td>final_mAP50-95</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>final_mAP50</td><td>0.995</td></tr><tr><td>final_mAP50-95</td><td>0.86363</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">yolov8n_cap_20251125_140200</strong> at: <a href='https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection/runs/uf3lsujy' target=\"_blank\">https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection/runs/uf3lsujy</a><br> View project at: <a href='https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection' target=\"_blank\">https://wandb.ai/afifahapriliani2000-mecata-foundation/bottle-cap-detection</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251125_140200-uf3lsujy/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "‚úÖ Training Complete!\n",
            "==================================================\n",
            "Best model: runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.pt\n",
            "\n",
            "Next steps:\n",
            "1. Check W&B dashboard for detailed metrics\n",
            "2. Test inference on sample images\n",
            "3. Deploy to edge device for real-world testing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Inference with Pytorch Model**"
      ],
      "metadata": {
        "id": "3vOamzEhSHf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# ================================\n",
        "# USER CONFIG ‚Äî EDIT DI SINI\n",
        "# ================================\n",
        "PATH_IMAGE = \"/content/tes11.jpg\"        # path ke gambar input\n",
        "PATH_MODEL = \"/content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.pt\"           # path ke YOLO model\n",
        "IMG_SIZE   = 320\n",
        "CONF_THRESH = 0.5\n",
        "OUTPUT_PATH = \"output.jpg\"\n",
        "RUN_BENCHMARK = False\n",
        "BENCHMARK_RUNS = 100\n",
        "# ================================\n",
        "\n",
        "\n",
        "class BottleCapDetector:\n",
        "    \"\"\"Bottle cap detector with color classification\"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str, imgsz: int = 320, conf: float = 0.5):\n",
        "        self.model = YOLO(model_path)\n",
        "        self.imgsz = imgsz\n",
        "        self.conf = conf\n",
        "        self.class_names = ['dark_blue', 'light_blue', 'others']\n",
        "        self.colors = {\n",
        "            0: (139, 0, 0),      # dark_blue BGR\n",
        "            1: (255, 200, 100),  # light_blue BGR\n",
        "            2: (128, 128, 128)   # others\n",
        "        }\n",
        "\n",
        "    def detect(self, image_path: str, visualize: bool = True):\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Cannot load image: {image_path}\")\n",
        "\n",
        "        start_time = time.time()\n",
        "        results = self.model(img, imgsz=self.imgsz, conf=self.conf, verbose=False)\n",
        "        inference_time = (time.time() - start_time) * 1000\n",
        "\n",
        "        detections = []\n",
        "        for r in results:\n",
        "            for box in r.boxes:\n",
        "                cls = int(box.cls[0])\n",
        "                conf = float(box.conf[0])\n",
        "                xyxy = box.xyxy[0].cpu().numpy()\n",
        "\n",
        "                detections.append({\n",
        "                    'class': self.class_names[cls],\n",
        "                    'confidence': conf,\n",
        "                    'bbox': xyxy.tolist()\n",
        "                })\n",
        "\n",
        "        output_img = None\n",
        "        if visualize:\n",
        "            output_img = self._visualize(img.copy(), detections)\n",
        "\n",
        "        return {\n",
        "            'detections': detections,\n",
        "            'inference_time_ms': inference_time,\n",
        "            'image': output_img\n",
        "        }\n",
        "\n",
        "    def _visualize(self, img, detections):\n",
        "        for det in detections:\n",
        "            x1, y1, x2, y2 = map(int, det['bbox'])\n",
        "            class_name = det['class']\n",
        "            conf = det['confidence']\n",
        "\n",
        "            color = self.colors[self.class_names.index(class_name)]\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "            label = f\"{class_name}: {conf:.2f}\"\n",
        "            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
        "\n",
        "            cv2.rectangle(img,\n",
        "                          (x1, y1 - label_size[1] - 10),\n",
        "                          (x1 + label_size[0], y1),\n",
        "                          color, -1)\n",
        "\n",
        "            cv2.putText(img, label, (x1, y1 - 5),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                        (255, 255, 255), 2)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def benchmark(self, image_path: str, num_runs: int = 100):\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Cannot load image: {image_path}\")\n",
        "\n",
        "        for _ in range(10):\n",
        "            _ = self.model(img, imgsz=self.imgsz, verbose=False)\n",
        "\n",
        "        times = []\n",
        "        for _ in range(num_runs):\n",
        "            start = time.time()\n",
        "            _ = self.model(img, imgsz=self.imgsz, verbose=False)\n",
        "            times.append((time.time() - start) * 1000)\n",
        "\n",
        "        return {\n",
        "            'avg_ms': np.mean(times),\n",
        "            'min_ms': np.min(times),\n",
        "            'max_ms': np.max(times),\n",
        "            'std_ms': np.std(times),\n",
        "            'fps': 1000 / np.mean(times)\n",
        "        }\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\" Bottle Cap Detector ‚Äî Auto Run Mode\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Model: {PATH_MODEL}\")\n",
        "    print(f\"Image: {PATH_IMAGE}\")\n",
        "\n",
        "    detector = BottleCapDetector(PATH_MODEL, IMG_SIZE, CONF_THRESH)\n",
        "\n",
        "    print(\"\\n Running detection...\")\n",
        "    result = detector.detect(PATH_IMAGE, visualize=True)\n",
        "\n",
        "    print(\"\\n Results:\")\n",
        "    print(f\"Inference time: {result['inference_time_ms']:.2f} ms\")\n",
        "    print(f\"Detections: {len(result['detections'])}\")\n",
        "\n",
        "    if result[\"detections\"]:\n",
        "        print(\"\\n Detected objects:\")\n",
        "        for i, det in enumerate(result[\"detections\"], 1):\n",
        "            print(f\"  {i}. {det['class']} ‚Äî {det['confidence']:.3f}\")\n",
        "    else:\n",
        "        print(\" No objects detected.\")\n",
        "\n",
        "    if result[\"image\"] is not None:\n",
        "        cv2.imwrite(OUTPUT_PATH, result[\"image\"])\n",
        "        print(f\"\\n Output saved to: {OUTPUT_PATH}\")\n",
        "\n",
        "    if RUN_BENCHMARK:\n",
        "        print(\"\\n Running benchmark...\")\n",
        "        stats = detector.benchmark(PATH_IMAGE, BENCHMARK_RUNS)\n",
        "\n",
        "        print(\"\\n Benchmark Results:\")\n",
        "        for k, v in stats.items():\n",
        "            print(f\"  {k}: {v:.2f}\")\n",
        "\n",
        "    print(\"\\n Done!\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LVRUURkVNRS",
        "outputId": "82b4b454-cf08-4ab4-abc0-385025bfe0cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            " Bottle Cap Detector ‚Äî Auto Run Mode\n",
            "============================================================\n",
            "Model: /content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.pt\n",
            "Image: /content/tes11.jpg\n",
            "\n",
            " Running detection...\n",
            "\n",
            " Results:\n",
            "Inference time: 123.59 ms\n",
            "Detections: 10\n",
            "\n",
            " Detected objects:\n",
            "  1. light_blue ‚Äî 0.966\n",
            "  2. light_blue ‚Äî 0.952\n",
            "  3. light_blue ‚Äî 0.934\n",
            "  4. light_blue ‚Äî 0.932\n",
            "  5. dark_blue ‚Äî 0.926\n",
            "  6. light_blue ‚Äî 0.924\n",
            "  7. dark_blue ‚Äî 0.918\n",
            "  8. dark_blue ‚Äî 0.915\n",
            "  9. dark_blue ‚Äî 0.885\n",
            "  10. dark_blue ‚Äî 0.858\n",
            "\n",
            " Output saved to: output.jpg\n",
            "\n",
            " Done!\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Inference with ONNX Model**"
      ],
      "metadata": {
        "id": "l8hs1D9TVNs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "import onnxruntime as ort\n",
        "\n",
        "\n",
        "# =====================================================\n",
        "# USER CONFIG ‚Äî EDIT DI SINI\n",
        "# =====================================================\n",
        "PATH_IMAGE = \"/content/tes11.jpg\"            # Path ke gambar input\n",
        "PATH_MODEL = \"/content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.onnx\"            # Path ke ONNX model\n",
        "IMG_SIZE = 320                       # Image size\n",
        "CONF_THRESH = 0.5                    # Confidence threshold\n",
        "OUTPUT_PATH = \"output_fast.jpg\"      # Output result\n",
        "RUN_BENCHMARK = False                # True = jalankan benchmark\n",
        "BENCHMARK_RUNS = 100                 # Jumlah iterasi benchmark\n",
        "# =====================================================\n",
        "\n",
        "\n",
        "class FastBottleCapDetector:\n",
        "    \"\"\"Optimized bottle cap detector using ONNX Runtime\"\"\"\n",
        "\n",
        "    def __init__(self, model_path: str, imgsz: int = 320, conf: float = 0.5):\n",
        "        self.imgsz = imgsz\n",
        "        self.conf = conf\n",
        "        self.class_names = ['dark_blue', 'light_blue', 'others']\n",
        "        self.colors = {\n",
        "            0: (139, 0, 0),\n",
        "            1: (255, 200, 100),\n",
        "            2: (128, 128, 128)\n",
        "        }\n",
        "\n",
        "        # Setup ONNX Runtime\n",
        "        sess_options = ort.SessionOptions()\n",
        "        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "        sess_options.intra_op_num_threads = 4\n",
        "        sess_options.inter_op_num_threads = 4\n",
        "\n",
        "        providers = ['CPUExecutionProvider']\n",
        "\n",
        "        if 'CUDAExecutionProvider' in ort.get_available_providers():\n",
        "            providers.insert(0, 'CUDAExecutionProvider')\n",
        "            print(\"Using CUDA acceleration\")\n",
        "        else:\n",
        "            print(\"Using CPU\")\n",
        "\n",
        "        self.session = ort.InferenceSession(\n",
        "            model_path,\n",
        "            sess_options=sess_options,\n",
        "            providers=providers\n",
        "        )\n",
        "\n",
        "        self.input_name = self.session.get_inputs()[0].name\n",
        "        self.output_names = [out.name for out in self.session.get_outputs()]\n",
        "\n",
        "        print(f\"Model loaded: {model_path}\")\n",
        "        print(f\"Input shape: {self.session.get_inputs()[0].shape}\")\n",
        "        print(f\"Output shape: {self.session.get_outputs()[0].shape}\")\n",
        "\n",
        "    def preprocess(self, img):\n",
        "        img_h, img_w = img.shape[:2]\n",
        "        scale = min(self.imgsz / img_w, self.imgsz / img_h)\n",
        "        new_w, new_h = int(img_w * scale), int(img_h * scale)\n",
        "\n",
        "        img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        img_padded = np.full((self.imgsz, self.imgsz, 3), 114, dtype=np.uint8)\n",
        "\n",
        "        pad_w = (self.imgsz - new_w) // 2\n",
        "        pad_h = (self.imgsz - new_h) // 2\n",
        "\n",
        "        img_padded[pad_h:pad_h+new_h, pad_w:pad_w+new_w] = img_resized\n",
        "        img_rgb = cv2.cvtColor(img_padded, cv2.COLOR_BGR2RGB)\n",
        "        img_normalized = img_rgb.astype(np.float32) / 255.0\n",
        "        img_transposed = np.transpose(img_normalized, (2, 0, 1))\n",
        "        img_batch = np.expand_dims(img_transposed, 0).astype(np.float32)\n",
        "\n",
        "        return img_batch, scale, (pad_w, pad_h)\n",
        "\n",
        "    def postprocess(self, outputs, orig_shape, scale, padding):\n",
        "        output = outputs[0]  # (1, 7, 2100)\n",
        "        predictions = output[0].T  # (2100, 7)\n",
        "\n",
        "        boxes_xywh = predictions[:, :4]\n",
        "        scores = predictions[:, 4:]\n",
        "\n",
        "        class_ids = np.argmax(scores, axis=1)\n",
        "        confidences = np.max(scores, axis=1)\n",
        "\n",
        "        mask = confidences > self.conf\n",
        "        boxes_xywh = boxes_xywh[mask]\n",
        "        class_ids = class_ids[mask]\n",
        "        confidences = confidences[mask]\n",
        "\n",
        "        if len(boxes_xywh) == 0:\n",
        "            return []\n",
        "\n",
        "        boxes_xyxy = np.zeros_like(boxes_xywh)\n",
        "        boxes_xyxy[:, 0] = boxes_xywh[:, 0] - boxes_xywh[:, 2] / 2\n",
        "        boxes_xyxy[:, 1] = boxes_xywh[:, 1] - boxes_xywh[:, 3] / 2\n",
        "        boxes_xyxy[:, 2] = boxes_xywh[:, 0] + boxes_xywh[:, 2] / 2\n",
        "        boxes_xyxy[:, 3] = boxes_xywh[:, 1] + boxes_xywh[:, 3] / 2\n",
        "\n",
        "        pad_w, pad_h = padding\n",
        "        boxes_xyxy[:, [0, 2]] -= pad_w\n",
        "        boxes_xyxy[:, [1, 3]] -= pad_h\n",
        "\n",
        "        boxes_xyxy /= scale\n",
        "\n",
        "        boxes_xyxy[:, [0, 2]] = np.clip(boxes_xyxy[:, [0, 2]], 0, orig_shape[1])\n",
        "        boxes_xyxy[:, [1, 3]] = np.clip(boxes_xyxy[:, [1, 3]], 0, orig_shape[0])\n",
        "\n",
        "        indices = self.nms(boxes_xyxy, confidences)\n",
        "\n",
        "        detections = []\n",
        "        for idx in indices:\n",
        "            detections.append({\n",
        "                'class': self.class_names[class_ids[idx]],\n",
        "                'confidence': float(confidences[idx]),\n",
        "                'bbox': boxes_xyxy[idx].tolist()\n",
        "            })\n",
        "\n",
        "        return detections\n",
        "\n",
        "    def nms(self, boxes, scores, iou_threshold=0.45):\n",
        "        x1 = boxes[:, 0]\n",
        "        y1 = boxes[:, 1]\n",
        "        x2 = boxes[:, 2]\n",
        "        y2 = boxes[:, 3]\n",
        "\n",
        "        areas = (x2 - x1) * (y2 - y1)\n",
        "        order = scores.argsort()[::-1]\n",
        "\n",
        "        keep = []\n",
        "        while order.size > 0:\n",
        "            i = order[0]\n",
        "            keep.append(i)\n",
        "\n",
        "            xx1 = np.maximum(x1[i], x1[order[1:]])\n",
        "            yy1 = np.maximum(y1[i], y1[order[1:]])\n",
        "            xx2 = np.minimum(x2[i], x2[order[1:]])\n",
        "            yy2 = np.minimum(y2[i], y2[order[1:]])\n",
        "\n",
        "            w = np.maximum(0.0, xx2 - xx1)\n",
        "            h = np.maximum(0.0, yy2 - yy1)\n",
        "            inter = w * h\n",
        "\n",
        "            iou = inter / (areas[i] + areas[order[1:]] - inter)\n",
        "            order = order[np.where(iou <= iou_threshold)[0] + 1]\n",
        "\n",
        "        return keep\n",
        "\n",
        "    def detect(self, image_path: str, visualize: bool = True):\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Cannot load image: {image_path}\")\n",
        "\n",
        "        orig_shape = img.shape[:2]\n",
        "        input_tensor, scale, padding = self.preprocess(img)\n",
        "\n",
        "        start = time.perf_counter()\n",
        "        outputs = self.session.run(self.output_names, {self.input_name: input_tensor})\n",
        "        inference_time = (time.perf_counter() - start) * 1000\n",
        "\n",
        "        detections = self.postprocess(outputs, orig_shape, scale, padding)\n",
        "\n",
        "        output_img = img.copy() if visualize else None\n",
        "\n",
        "        if visualize:\n",
        "            for det in detections:\n",
        "                x1, y1, x2, y2 = map(int, det['bbox'])\n",
        "\n",
        "                color = self.colors[self.class_names.index(det['class'])]\n",
        "                cv2.rectangle(output_img, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "                label = f\"{det['class']}: {det['confidence']:.2f}\"\n",
        "                cv2.putText(output_img, label, (x1, y1 - 5),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                            (255, 255, 255), 2)\n",
        "\n",
        "        return {\n",
        "            'detections': detections,\n",
        "            'inference_time_ms': inference_time,\n",
        "            'image': output_img\n",
        "        }\n",
        "\n",
        "    def benchmark(self, image_path: str, num_runs: int = 100):\n",
        "        img = cv2.imread(image_path)\n",
        "        if img is None:\n",
        "            raise ValueError(f\"Cannot load image: {image_path}\")\n",
        "\n",
        "        input_tensor, _, _ = self.preprocess(img)\n",
        "\n",
        "        for _ in range(20):\n",
        "            _ = self.session.run(self.output_names, {self.input_name: input_tensor})\n",
        "\n",
        "        times = []\n",
        "        for _ in range(num_runs):\n",
        "            start = time.perf_counter()\n",
        "            _ = self.session.run(self.output_names, {self.input_name: input_tensor})\n",
        "            times.append((time.perf_counter() - start) * 1000)\n",
        "\n",
        "        times = np.array(times)\n",
        "\n",
        "        return {\n",
        "            'avg_ms': np.mean(times),\n",
        "            'min_ms': np.min(times),\n",
        "            'max_ms': np.max(times),\n",
        "            'std_ms': np.std(times),\n",
        "            'fps': 1000 / np.mean(times)\n",
        "        }\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 70)\n",
        "    print(\"FAST BOTTLE CAP DETECTOR ‚Äî AUTO RUN MODE\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Model: {PATH_MODEL}\")\n",
        "    print(f\"Image: {PATH_IMAGE}\")\n",
        "\n",
        "    detector = FastBottleCapDetector(PATH_MODEL, IMG_SIZE, CONF_THRESH)\n",
        "\n",
        "    print(\"\\n Running detection...\")\n",
        "    result = detector.detect(PATH_IMAGE, visualize=True)\n",
        "\n",
        "    print(\"\\n Results:\")\n",
        "    print(f\"  Inference time: {result['inference_time_ms']:.2f} ms\")\n",
        "    print(f\"  Detections: {len(result['detections'])}\")\n",
        "\n",
        "    for i, det in enumerate(result['detections'], 1):\n",
        "        print(f\"  {i}. {det['class']} ‚Äî {det['confidence']:.3f}\")\n",
        "\n",
        "    if result[\"image\"] is not None:\n",
        "        cv2.imwrite(OUTPUT_PATH, result[\"image\"])\n",
        "        print(f\"\\n Output saved to: {OUTPUT_PATH}\")\n",
        "\n",
        "    if RUN_BENCHMARK:\n",
        "        print(\"\\n Running benchmark...\")\n",
        "        stats = detector.benchmark(PATH_IMAGE, BENCHMARK_RUNS)\n",
        "\n",
        "        print(\"\\n Benchmark Results:\")\n",
        "        for k, v in stats.items():\n",
        "            print(f\"  {k}: {v:.2f}\")\n",
        "\n",
        "    print(\"\\n DONE!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpVWTMiRSVXz",
        "outputId": "b2da4487-54bb-4c7d-d330-c836e84015e9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FAST BOTTLE CAP DETECTOR ‚Äî AUTO RUN MODE\n",
            "======================================================================\n",
            "Model: /content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.onnx\n",
            "Image: /content/tes11.jpg\n",
            "Using CPU\n",
            "Model loaded: /content/runs/train_bottle_cap/yolov8n_cap_20251125_140200/weights/best.onnx\n",
            "Input shape: [1, 3, 320, 320]\n",
            "Output shape: [1, 7, 2100]\n",
            "\n",
            " Running detection...\n",
            "\n",
            " Results:\n",
            "  Inference time: 144.65 ms\n",
            "  Detections: 10\n",
            "  1. light_blue ‚Äî 0.966\n",
            "  2. light_blue ‚Äî 0.952\n",
            "  3. light_blue ‚Äî 0.934\n",
            "  4. light_blue ‚Äî 0.932\n",
            "  5. dark_blue ‚Äî 0.926\n",
            "  6. light_blue ‚Äî 0.924\n",
            "  7. dark_blue ‚Äî 0.918\n",
            "  8. dark_blue ‚Äî 0.915\n",
            "  9. dark_blue ‚Äî 0.885\n",
            "  10. dark_blue ‚Äî 0.858\n",
            "\n",
            " Output saved to: output_fast.jpg\n",
            "\n",
            " DONE!\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}